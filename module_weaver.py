import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pypdf import PdfReader
from docx import Document
from bs4 import BeautifulSoup
from streamlit_agraph import agraph, Node, Edge, Config
import plotly.express as px
import time
from datetime import datetime
import json
import re

# ‚úÖ [S·ª¨A] THAY TH·∫æ GSPREAD B·∫∞NG SUPABASE
try:
    from supabase import create_client, Client
except ImportError:
    st.error("‚ö†Ô∏è Thi·∫øu th∆∞ vi·ªán supabase. H√£y th√™m 'supabase' v√†o requirements.txt")

# --- IMPORT C√ÅC META-BLOCKS ---
from ai_core import AI_Core
from voice_block import Voice_Engine
from prompts import DEBATE_PERSONAS, BOOK_ANALYSIS_PROMPT

# ==========================================
# ‚úÖ [S·ª¨A] C·∫§U H√åNH K·∫æT N·ªêI SUPABASE
# ==========================================
has_db = False
supabase = None

try:
    # L·∫•y key t·ª´ secrets.toml
    SUPA_URL = st.secrets["supabase"]["url"]
    SUPA_KEY = st.secrets["supabase"]["key"]
    supabase: Client = create_client(SUPA_URL, SUPA_KEY)
    has_db = True
except Exception as e:
    # N·∫øu ch∆∞a c·∫•u h√¨nh th√¨ th√¥i, ch·ªâ t·∫Øt t√≠nh nƒÉng log
    pass

# ==========================================
# üåç B·ªò T·ª™ ƒêI·ªÇN ƒêA NG√îN NG·ªÆ
# ==========================================
TRANS = {
    "vi": {
        "lang_select": "Ng√¥n ng·ªØ / Language / ËØ≠Ë®Ä",
        "tab1": "üìö Ph√¢n T√≠ch S√°ch",
        "tab2": "‚úçÔ∏è D·ªãch Gi·∫£",
        "tab3": "üó£Ô∏è Tranh Bi·ªán",
        "tab4": "üéôÔ∏è Ph√≤ng Thu AI",
        "tab5": "‚è≥ Nh·∫≠t K√Ω",
        "t1_header": "Tr·ª£ l√Ω Nghi√™n c·ª©u & Knowledge Graph",
        "t1_up_excel": "1. K·∫øt n·ªëi Kho S√°ch (Excel)",
        "t1_up_doc": "2. T√†i li·ªáu m·ªõi (PDF/Docx)",
        "t1_btn": "üöÄ PH√ÇN T√çCH NGAY",
        "t1_analyzing": "ƒêang ph√¢n t√≠ch {name}...",
        "t1_connect_ok": "‚úÖ ƒê√£ k·∫øt n·ªëi {n} cu·ªën s√°ch.",
        "t1_graph_title": "ü™ê V≈© Tr·ª• S√°ch",
        "t2_header": "D·ªãch Thu·∫≠t ƒêa Chi·ªÅu",
        "t2_input": "Nh·∫≠p vƒÉn b·∫£n c·∫ßn d·ªãch:",
        "t2_target": "D·ªãch sang:",
        "t2_style": "Phong c√°ch:",
        "t2_btn": "‚úçÔ∏è D·ªãch Ngay",
        "t3_header": "ƒê·∫•u Tr∆∞·ªùng T∆∞ Duy",
        "t3_persona_label": "Ch·ªçn ƒê·ªëi Th·ªß:",
        "t3_input": "Nh·∫≠p ch·ªß ƒë·ªÅ tranh lu·∫≠n...",
        "t3_clear": "üóëÔ∏è X√≥a Chat",
        "t4_header": "üéôÔ∏è Ph√≤ng Thu AI ƒêa Ng√¥n Ng·ªØ",
        "t4_voice": "Ch·ªçn Gi·ªçng:",
        "t4_speed": "T·ªëc ƒë·ªô:",
        "t4_btn": "üîä T·∫†O AUDIO",
        "t5_header": "Nh·∫≠t K√Ω & L·ªãch S·ª≠",
        "t5_refresh": "üîÑ T·∫£i l·∫°i L·ªãch s·ª≠",
        "t5_empty": "Ch∆∞a c√≥ d·ªØ li·ªáu l·ªãch s·ª≠.",
    },
    "en": {
        "lang_select": "Language",
        "tab1": "üìö Book Analysis",
        "tab2": "‚úçÔ∏è Translator",
        "tab3": "üó£Ô∏è Debater",
        "tab4": "üéôÔ∏è AI Studio",
        "tab5": "‚è≥ History",
        "t1_header": "Research Assistant & Knowledge Graph",
        "t1_up_excel": "1. Connect Book Database (Excel)",
        "t1_up_doc": "2. New Documents (PDF/Docx)",
        "t1_btn": "üöÄ ANALYZE NOW",
        "t1_analyzing": "Analyzing {name}...",
        "t1_connect_ok": "‚úÖ Connected {n} books.",
        "t1_graph_title": "ü™ê Book Universe",
        "t2_header": "Multidimensional Translator",
        "t2_input": "Enter text to translate:",
        "t2_target": "Translate to:",
        "t2_style": "Style:",
        "t2_btn": "‚úçÔ∏è Translate",
        "t3_header": "Thinking Arena",
        "t3_persona_label": "Choose Opponent:",
        "t3_input": "Enter debate topic...",
        "t3_clear": "üóëÔ∏è Clear Chat",
        "t4_header": "üéôÔ∏è Multilingual AI Studio",
        "t4_voice": "Select Voice:",
        "t4_speed": "Speed:",
        "t4_btn": "üîä GENERATE AUDIO",
        "t5_header": "Logs & History",
        "t5_refresh": "üîÑ Refresh History",
        "t5_empty": "No history data found.",
    },
    "zh": {
        "lang_select": "ËØ≠Ë®Ä",
        "tab1": "üìö ‰π¶Á±çÂàÜÊûê",
        "tab2": "‚úçÔ∏è ÁøªËØë‰∏ìÂÆ∂",
        "tab3": "üó£Ô∏è Ëæ©ËÆ∫Âú∫",
        "tab4": "üéôÔ∏è AI ÂΩïÈü≥ÂÆ§",
        "tab5": "‚è≥ ÂéÜÂè≤ËÆ∞ÂΩï",
        "t1_header": "Á†îÁ©∂Âä©Êâã & Áü•ËØÜÂõæË∞±",
        "t1_up_excel": "1. ËøûÊé•‰π¶Â∫ì (Excel)",
        "t1_up_doc": "2. ‰∏ä‰º†Êñ∞ÊñáÊ°£ (PDF/Docx)",
        "t1_btn": "üöÄ Á´ãÂç≥ÂàÜÊûê",
        "t1_analyzing": "Ê≠£Âú®ÂàÜÊûê {name}...",
        "t1_connect_ok": "‚úÖ Â∑≤ËøûÊé• {n} Êú¨‰π¶„ÄÇ",
        "t1_graph_title": "ü™ê ‰π¶Á±çÂÆáÂÆô",
        "t2_header": "Â§öÁª¥ÁøªËØë",
        "t2_input": "ËæìÂÖ•ÊñáÊú¨:",
        "t2_target": "ÁøªËØëÊàê:",
        "t2_style": "È£éÊ†º:",
        "t2_btn": "‚úçÔ∏è ÁøªËØë",
        "t3_header": "ÊÄùÁª¥Á´ûÊäÄÂú∫",
        "t3_persona_label": "ÈÄâÊã©ÂØπÊâã:",
        "t3_input": "ËæìÂÖ•Ëæ©ËÆ∫‰∏ªÈ¢ò...",
        "t3_clear": "üóëÔ∏è Ê∏ÖÈô§ËÅäÂ§©",
        "t4_header": "üéôÔ∏è AI Â§öËØ≠Ë®ÄÂΩïÈü≥ÂÆ§",
        "t4_voice": "ÈÄâÊã©Â£∞Èü≥:",
        "t4_speed": "ËØ≠ÈÄü:",
        "t4_btn": "üîä ÁîüÊàêÈü≥È¢ë",
        "t5_header": "Êó•Âøó & ÂéÜÂè≤",
        "t5_refresh": "üîÑ Âà∑Êñ∞ÂéÜÂè≤",
        "t5_empty": "ÊöÇÊó†ÂéÜÂè≤Êï∞ÊçÆ„ÄÇ",
    }
}

# H√†m l·∫•y text theo ng√¥n ng·ªØ
def T(key):
    lang = st.session_state.get('weaver_lang', 'vi')
    return TRANS.get(lang, TRANS['vi']).get(key, key)

# --- C√ÅC H√ÄM PH·ª§ TR·ª¢ (ƒê√É S·ª¨A THEO Y√äU C·∫¶U) ---
@st.cache_resource
def load_models():
    """Ch·ªâ load khi th·ª±c s·ª± c·∫ßn, v√† gi·ªõi h·∫°n 1 instance"""
    try:
        model = SentenceTransformer(
            "paraphrase-multilingual-MiniLM-L12-v2",
            device='cpu'  # ‚Üê B·∫ÆT BU·ªòC d√πng CPU tr√™n Streamlit Cloud
        )
        # Gi·∫£m k√≠ch th∆∞·ªõc cache
        model.max_seq_length = 128  # Gi·∫£m t·ª´ 256 (default)
        return model
    except Exception as e:
        # st.error(f"Kh√¥ng load ƒë∆∞·ª£c model: {e}")
        return None

# TH√äM H√ÄM KI·ªÇM TRA
def check_model_available():
    """Ki·ªÉm tra model c√≥ s·∫µn kh√¥ng tr∆∞·ªõc khi d√πng"""
    model = load_models()
    if model is None:
        st.warning("‚ö†Ô∏è Ch·ª©c nƒÉng Knowledge Graph t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng (thi·∫øu RAM)")
        return False
    return True

def doc_file(uploaded_file):
    if not uploaded_file: return ""
    ext = uploaded_file.name.split('.')[-1].lower()
    try:
        if ext == "pdf":
            reader = PdfReader(uploaded_file)
            return "\n".join([page.extract_text() for page in reader.pages])
        elif ext == "docx":
            doc = Document(uploaded_file)
            return "\n".join([p.text for p in doc.paragraphs])
        elif ext in ["txt", "md", "html"]:
            return str(uploaded_file.read(), "utf-8")
    except: return ""
    return ""

# ==========================================
# ‚úÖ [S·ª¨A] C√ÅC H√ÄM T∆Ø∆†NG T√ÅC DB (THAY GSPREAD)
# ==========================================

def luu_lich_su(loai, tieu_de, noi_dung):
    """L∆∞u log v√†o Supabase"""
    if not has_db: return
    
    user = st.session_state.get("current_user", "Unknown")
    
    # Map d·ªØ li·ªáu v√†o ƒë√∫ng t√™n c·ªôt trong Supabase (ch·ªØ th∆∞·ªùng)
    data = {
        "type": loai,
        "title": tieu_de,
        "content": noi_dung,
        "user_name": user,
        "sentiment_score": 0.0,
        "sentiment_label": "Neutral"
    }
    
    try:
        # insert v√†o b·∫£ng history_logs
        supabase.table("History_Logs").insert(data).execute()
    except Exception as e:
        print(f"L·ªói l∆∞u log: {e}")

def tai_lich_su():
    """T·∫£i log t·ª´ Supabase v√† chuy·ªÉn v·ªÅ format c≈© cho Frontend"""
    if not has_db: return []
    
    try:
        # L·∫•y 50 d√≤ng m·ªõi nh·∫•t
        response = supabase.table("History_Logs").select("*").order("created_at", desc=True).limit(50).execute()
        raw_data = response.data
        
        # ‚úÖ QUAN TR·ªåNG: Map l·∫°i t√™n c·ªôt ƒë·ªÉ kh·ªõp v·ªõi code Frontend c≈© c·ªßa ch·ªã
        # Supabase tr·∫£ v·ªÅ: created_at, type, title...
        # Ch·ªã c·∫ßn: Time, Type, Title...
        formatted_data = []
        for item in raw_data:
            # X·ª≠ l√Ω ng√†y th√°ng: "2023-10-10T10:00:00" -> "2023-10-10 10:00:00"
            raw_time = item.get("created_at", "")
            clean_time = raw_time.replace("T", " ")[:19]

            formatted_data.append({
                "Time": clean_time,            # Map created_at -> Time
                "Type": item.get("type"),      # Map type -> Type
                "Title": item.get("title"),    # Map title -> Title
                "Content": item.get("content"),# Map content -> Content
                "User": item.get("user_name"), # Map user_name -> User
                "SentimentScore": item.get("sentiment_score", 0.0),
                "SentimentLabel": item.get("sentiment_label", "Neutral")
            })
            
        return formatted_data
    except Exception as e:
        # st.error(f"L·ªói t·∫£i l·ªãch s·ª≠ t·ª´ DB: {e}")
        return []

# --- H√ÄM CH√çNH: RUN() ---
def run():
    # 1. Kh·ªüi t·∫°o c√°c Block
    ai = AI_Core()
    voice = Voice_Engine()
    
    # 2. Sidebar ch·ªçn ng√¥n ng·ªØ cho Module n√†y
    with st.sidebar:
        st.markdown("---")
        lang_choice = st.selectbox(
            "üåê " + TRANS['vi']['lang_select'],
            ["Ti·∫øng Vi·ªát", "English", "‰∏≠Êñá"],
            index=0,
            key="weaver_lang_selector"
        )
        # L∆∞u ng√¥n ng·ªØ v√†o session state
        if lang_choice == "Ti·∫øng Vi·ªát": st.session_state.weaver_lang = 'vi'
        elif lang_choice == "English": st.session_state.weaver_lang = 'en'
        elif lang_choice == "‰∏≠Êñá": st.session_state.weaver_lang = 'zh'
    
    st.header(f"üß† The Cognitive Weaver")
    
    # 5 TABS ƒê·∫¶Y ƒê·ª¶ (D√πng h√†m T ƒë·ªÉ d·ªãch t√™n Tab)
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        T("tab1"), T("tab2"), T("tab3"), T("tab4"), T("tab5")
    ])

    # === TAB 1: RAG & GRAPH ===
    with tab1:
        st.subheader(T("t1_header"))
        
        c1, c2, c3 = st.columns([1, 1, 1])
        with c1: file_excel = st.file_uploader(T("t1_up_excel"), type="xlsx", key="w_t1_ex")
        with c2: uploaded_files = st.file_uploader(T("t1_up_doc"), type=["pdf", "docx", "txt"], accept_multiple_files=True, key="w_t1_doc")
        with c3: 
            st.write("")
            st.write("")
            btn_run = st.button(T("t1_btn"), type="primary", use_container_width=True)

        if btn_run and uploaded_files:
            # ‚úÖ TH√äM: Progress Bar & Status
            total_files = len(uploaded_files)
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            vec = load_models()
            db, df = None, None
            has_db_rag = False
            
            if file_excel:
                try:
                    df = pd.read_excel(file_excel).dropna(subset=["T√™n s√°ch"])
                    db = vec.encode([f"{r['T√™n s√°ch']} {str(r.get('C·∫¢M NH·∫¨N',''))}" for _, r in df.iterrows()])
                    has_db_rag = True
                    st.success(T("t1_connect_ok").format(n=len(df)))
                except: st.error("L·ªói ƒë·ªçc Excel.")

            # ‚úÖ TH√äM: D√πng enumerate ƒë·ªÉ theo d√µi ti·∫øn ƒë·ªô
            for file_idx, f in enumerate(uploaded_files):
                # Update status
                status_text.text(f"ƒêang x·ª≠ l√Ω file {file_idx+1}/{total_files}: {f.name}")
                progress_bar.progress((file_idx) / total_files)
                
                # Logic x·ª≠ l√Ω file c≈©
                text = doc_file(f)
                link = ""
                if has_db_rag and vec:
                    q = vec.encode([text[:2000]])
                    sc = cosine_similarity(q, db)[0]
                    # L∆∞u √Ω: ƒê·ªïi t√™n bi·∫øn idx th√†nh idx_sim ƒë·ªÉ tr√°nh tr√πng
                    idx_sim = np.argsort(sc)[::-1][:3]
                    for i in idx_sim:
                        if sc[i] > 0.35: link += f"- {df.iloc[i]['T√™n s√°ch']} ({sc[i]*100:.0f}%)\n"

                with st.spinner(T("t1_analyzing").format(name=f.name)):
                    prompt = f"Ph√¢n t√≠ch t√†i li·ªáu '{f.name}'. Li√™n quan: {link}\nN·ªôi dung: {text[:30000]}"
                    res = ai.analyze_static(prompt, BOOK_ANALYSIS_PROMPT)
                    
                    st.markdown(f"### üìÑ {f.name}")
                    st.markdown(res)
                    st.markdown("---")
                    luu_lich_su("Ph√¢n T√≠ch S√°ch", f.name, res[:200])
                
                # Update progress sau khi xong 1 file
                progress_bar.progress((file_idx+1) / total_files)
            
            status_text.text("‚úÖ Ho√†n th√†nh!")

        # V·∫º GRAPH (AGRAPH)
        if file_excel:
            try:
                with st.expander(T("t1_graph_title"), expanded=False):
                    vec = load_models()
                    if "book_embs" not in st.session_state:
                         st.session_state.book_embs = vec.encode(df["T√™n s√°ch"].tolist())
                    
                    embs = st.session_state.book_embs
                    sim = cosine_similarity(embs)
                    nodes, edges = [], []
                    
                    max_nodes = st.slider("Max Nodes:", 5, len(df), min(50, len(df)))
                    threshold = st.slider("Threshold:", 0.0, 1.0, 0.45)

                    for i in range(max_nodes):
                        nodes.append(Node(id=str(i), label=df.iloc[i]["T√™n s√°ch"], size=20, color="#FFD166"))
                        for j in range(i+1, max_nodes):
                            if sim[i,j]>threshold: edges.append(Edge(source=str(i), target=str(j), color="#118AB2"))
                    
                    config = Config(width=900, height=600, directed=False, physics=True, collapsible=False)
                    agraph(nodes, edges, config)
            except: pass

    # === TAB 2: D·ªäCH GI·∫¢ ===
    with tab2:
        st.subheader(T("t2_header"))
        txt = st.text_area(T("t2_input"), height=150, key="w_t2_inp")
        c_l, c_s, c_b = st.columns([1,1,1])
        with c_l: target_lang = st.selectbox(T("t2_target"), ["Ti·∫øng Vi·ªát", "English", "Chinese", "French", "Japanese"], key="w_t2_lang")
        with c_s: style = st.selectbox(T("t2_style"), ["Default", "Academic", "Literary", "Business"], key="w_t2_style")
        
        if st.button(T("t2_btn"), key="w_t2_btn") and txt:
            with st.spinner("AI Translating..."):
                p = f"Translate to {target_lang}. Style: {style}. Text: {txt}"
                res = ai.generate(p, model_type="pro")
                st.markdown(res)
                luu_lich_su("D·ªãch Thu·∫≠t", f"{target_lang}", txt[:50])

    # === TAB 3: ƒê·∫§U TR∆Ø·ªúNG T∆Ø DUY ===
    with tab3:
        st.subheader(T("t3_header"))
        mode = st.radio("Mode:", ["üë§ Solo", "‚öîÔ∏è Multi-Agent"], horizontal=True, key="w_t3_mode")
        
        # Kh·ªüi t·∫°o history n·∫øu ch∆∞a c√≥
        if "weaver_chat" not in st.session_state: 
            st.session_state.weaver_chat = []

        # ========================================
        # MODE 1: SOLO (USER vs AI v·ªõi MEMORY)
        # ========================================
        if mode == "üë§ Solo":
            c1, c2 = st.columns([3, 1])
            
            with c1: 
                persona = st.selectbox(
                    T("t3_persona_label"), 
                    list(DEBATE_PERSONAS.keys()), 
                    key="w_t3_solo_p"
                )
            
            with c2: 
                if st.button(T("t3_clear"), key="w_t3_clr"): 
                    st.session_state.weaver_chat = []
                    st.rerun()

            # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
            for msg in st.session_state.weaver_chat:
                st.chat_message(msg["role"]).write(msg["content"])

            # Input m·ªõi
            if prompt := st.chat_input(T("t3_input")):
                # Th√™m user message
                st.chat_message("user").write(prompt)
                st.session_state.weaver_chat.append({
                    "role": "user", 
                    "content": prompt
                })
                
                # X√ÇY D·ª∞NG CONTEXT T·ª™ L·ªäCH S·ª¨
                recent_history = st.session_state.weaver_chat[-10:]
                
                context_text = "\n".join([
                    f"{m['role'].upper()}: {m['content']}" 
                    for m in recent_history
                ])
                
                # Prompt c√≥ ng·ªØ c·∫£nh ƒë·∫ßy ƒë·ªß
                full_prompt = f"""
                L·ªäCH S·ª¨ H·ªòI THO·∫†I:
                {context_text}

                NHI·ªÜM V·ª§: D·ª±a v√†o l·ªãch s·ª≠ tr√™n, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªõi nh·∫•t c·ªßa USER.
                N·∫øu USER h·ªèi "c√¢u h·ªèi c≈©" ho·∫∑c "v·ª´a r·ªìi", h√£y tham chi·∫øu ƒë·∫øn l·ªãch s·ª≠ ƒë·ªÉ tr·∫£ l·ªùi.
                """
                
                with st.chat_message("assistant"):
                    sys_instruction = DEBATE_PERSONAS[persona]
                    
                    with st.spinner("ü§î ƒêang suy nghƒ©..."):
                        # G·ªçi AI v·ªõi context ƒë·∫ßy ƒë·ªß
                        res = ai.generate(
                            full_prompt, 
                            model_type="flash", 
                            system_instruction=sys_instruction
                        )
                        
                        if res:
                            st.write(res)
                            
                            # L∆∞u assistant response
                            st.session_state.weaver_chat.append({
                                "role": "assistant", 
                                "content": res
                            })
                            
                            # L∆ØU C·∫¢ C√ÇU H·ªéI V√Ä TR·∫¢ L·ªúI
                            full_content = f"""
                            üë§ USER: {prompt}

                            ü§ñ {persona}: {res}
                            """
                            
                            luu_lich_su(
                                loai="Tranh Bi·ªán Solo",
                                tieu_de=f"{persona} - {prompt[:50]}...",
                                noi_dung=full_content.strip()
                            )
                        else:
                            st.error("‚ö†Ô∏è AI kh√¥ng ph·∫£n h·ªìi. Vui l√≤ng th·ª≠ l·∫°i.")
        
        # ========================================
        # MODE 2: MULTI-AGENT (AI vs AI) - ƒê√É S·ª¨A THEO Y√äU C·∫¶U
        # ========================================
        else:
            st.info("üí° Ch·ªçn 2-3 nh√¢n v·∫≠t ƒë·ªÉ h·ªç t·ª± tranh lu·∫≠n.")
            
            participants = st.multiselect(
                "Ch·ªçn H·ªôi ƒê·ªìng Tranh Bi·ªán:", 
                list(DEBATE_PERSONAS.keys()), 
                default=[list(DEBATE_PERSONAS.keys())[0], list(DEBATE_PERSONAS.keys())[1]],
                max_selections=3,
                key="w_t3_multi_p"
            )
            
            topic = st.text_input(
                "Ch·ªß ƒë·ªÅ tranh lu·∫≠n:", 
                placeholder="VD: Ti·ªÅn c√≥ mua ƒë∆∞·ª£c h·∫°nh ph√∫c kh√¥ng?",
                key="w_t3_topic"
            )
            
            c_start, c_del = st.columns([1, 5])
            
            with c_start:
                start_btn = st.button(
                    "üî• KHAI CHI·∫æN", 
                    key="w_t3_start", 
                    disabled=(len(participants) < 2 or not topic),
                    type="primary"
                )
            
            with c_del:
                if st.button("üóëÔ∏è X√≥a B√†n", key="w_t3_multi_clr"):
                    st.session_state.weaver_chat = []
                    st.rerun()

            # Hi·ªÉn th·ªã l·ªãch s·ª≠ c≈©
            for msg in st.session_state.weaver_chat:
                role = msg["role"]
                content = msg["content"]
                
                if role == "system":
                    st.info(content)
                else:
                    st.chat_message("assistant").write(content)
            
            # === PH·∫¶N LOGIC ƒê∆Ø·ª¢C S·ª¨A ===
            if start_btn and topic and len(participants) >= 2:
                st.session_state.weaver_chat = []
                
                start_msg = f"üì¢ **CH·ª¶ T·ªåA:** Khai m·∫°c tranh lu·∫≠n v·ªÅ: *'{topic}'*"
                st.session_state.weaver_chat.append({"role": "system", "content": start_msg})
                st.info(start_msg)
                
                full_transcript = [start_msg]
                
                # ‚úÖ TH√äM: Timeout to√†n b·ªô cu·ªôc tranh lu·∫≠n
                MAX_DEBATE_TIME = 90  # 90 gi√¢y
                start_time = time.time()
                
                with st.status("üî• Cu·ªôc chi·∫øn ƒëang di·ªÖn ra (t·ªëi ƒëa 3 v√≤ng)...") as status:
                    try:
                        for round_num in range(1, 4):
                            # ‚úÖ KI·ªÇM TRA TIMEOUT
                            if time.time() - start_time > MAX_DEBATE_TIME:
                                st.warning("‚è∞ ƒê√£ h·∫øt th·ªùi gian tranh lu·∫≠n (90s). K·∫øt th√∫c s·ªõm.")
                                break
                            
                            status.update(label=f"üîÑ V√≤ng {round_num}/3 ƒëang di·ªÖn ra...")
                            
                            for i, p_name in enumerate(participants):
                                # ‚úÖ KI·ªÇM TRA TIMEOUT CHO T·ª™NG NG∆Ø·ªúI
                                if time.time() - start_time > MAX_DEBATE_TIME:
                                    break
                                
                                # L·∫•y ng·ªØ c·∫£nh (gi·ªØ nguy√™n logic c≈©)
                                if len(st.session_state.weaver_chat) > 1:
                                    recent_context = st.session_state.weaver_chat[-3:]
                                    context_str = "\n".join([
                                        f"- {m['content']}" 
                                        for m in recent_context 
                                        if m['role'] != 'system'
                                    ])
                                else:
                                    context_str = topic
                                
                                # X√¢y d·ª±ng prompt (gi·ªØ nguy√™n)
                                if round_num == 1:
                                    p_prompt = f"""
                                    CH·ª¶ ƒê·ªÄ TRANH LU·∫¨N: {topic}

                                    NHI·ªÜM V·ª§ (V√≤ng 1 - Khai m·∫°c): 
                                    B·∫°n l√† {p_name}. H√£y ƒë∆∞a ra quan ƒëi·ªÉm m·ªü ƒë·∫ßu c·ªßa m√¨nh v·ªÅ ch·ªß ƒë·ªÅ n√†y.
                                    N√™u r√µ l·∫≠p tr∆∞·ªùng v√† 2-3 l√Ω l·∫Ω ch√≠nh (d∆∞·ªõi 200 t·ª´).
                                    """
                                else:
                                    p_prompt = f"""
                                    CH·ª¶ ƒê·ªÄ: {topic}

                                    T√åNH HU·ªêNG HI·ªÜN T·∫†I:
                                    {context_str}

                                    NHI·ªÜM V·ª§ (V√≤ng {round_num} - Ph·∫£n bi·ªán):
                                    B·∫°n l√† {p_name}. H√£y:
                                    1. Ch·ªâ ra ƒëi·ªÉm y·∫øu trong l·∫≠p lu·∫≠n c·ªßa ƒë·ªëi th·ªß
                                    2. C·ªßng c·ªë quan ƒëi·ªÉm c·ªßa m√¨nh
                                    3. ƒê∆∞a ra th√™m 1 v√≠ d·ª• minh h·ªça
                                    (D∆∞·ªõi 200 t·ª´, s√∫c t√≠ch)
                                    """
                                
                                try:
                                    # ‚úÖ GI·∫¢M TH·ªúI GIAN CH·ªú V√Ä D√ôNG FLASH
                                    res = ai.generate(
                                        p_prompt, 
                                        model_type="flash",  # ‚Üê B·∫ÆT BU·ªòC d√πng Flash (Pro qu√° ch·∫≠m)
                                        system_instruction=DEBATE_PERSONAS[p_name]
                                    )
                                    
                                    if res:
                                        content_fmt = f"**{p_name}:** {res}"
                                        st.session_state.weaver_chat.append({
                                            "role": "assistant", 
                                            "content": content_fmt
                                        })
                                        full_transcript.append(content_fmt)
                                        
                                        with st.chat_message("assistant"):
                                            st.write(content_fmt)
                                        
                                        # ‚úÖ GI·∫¢M SLEEP: 6s ‚Üí 2s
                                        time.sleep(2)
                                    
                                except Exception as e:
                                    st.error(f"‚ö†Ô∏è L·ªói khi g·ªçi AI cho {p_name}: {str(e)}")
                                    continue  # ‚Üê B·ªè qua ng∆∞·ªùi n√†y, ti·∫øp t·ª•c v·ªõi ng∆∞·ªùi kh√°c
                        
                        status.update(label="‚úÖ Tranh lu·∫≠n k·∫øt th√∫c!", state="complete")
                        
                    except Exception as e:
                        st.error(f"‚ùå L·ªói nghi√™m tr·ªçng: {e}")
                        status.update(label="‚ùå Tranh lu·∫≠n g·∫∑p l·ªói", state="error")
                
                # L∆∞u l·ªãch s·ª≠
                full_log = "\n\n".join(full_transcript)
                
                luu_lich_su(
                    loai="H·ªôi ƒê·ªìng Tranh Bi·ªán",
                    tieu_de=f"Ch·ªß ƒë·ªÅ: {topic}",
                    noi_dung=full_log
                )
                
                st.toast("üíæ ƒê√£ l∆∞u bi√™n b·∫£n cu·ªôc h·ªçp v√†o Nh·∫≠t K√Ω!", icon="‚úÖ")
                
                with st.expander("üìÑ Xem To√†n B·ªô Bi√™n B·∫£n", expanded=False):
                    st.markdown(full_log)

    # === TAB 4: PH√íNG THU AI ===
    with tab4:
        st.subheader(T("t4_header"))
        c_in, c_ctrl = st.columns([3, 1])
        with c_in: inp_v = st.text_area("Text:", height=200, key="w_t4_input")
        with c_ctrl:
            try:
                v_choice = st.selectbox(T("t4_voice"), list(voice.VOICE_OPTIONS.keys()), key="w_t4_sel")
            except:
                v_choice = st.selectbox(T("t4_voice"), ["vi", "en"], key="w_t4_sel")
            speed_v = st.slider(T("t4_speed"), -50, 50, 0, key="w_t4_spd")
        
        if st.button(T("t4_btn"), key="w_t4_btn") and inp_v:
            with st.spinner("..."):
                path = voice.speak(inp_v, voice_key=v_choice, speed=speed_v)
                if path:
                    st.audio(path)
                    st.success("OK")

    # === TAB 5: NH·∫¨T K√ù & T∆Ø DUY BAYES ===
    with tab5:
        st.subheader("‚è≥ Nh·∫≠t K√Ω & Ph·∫£n Chi·∫øu T∆∞ Duy")
        
        col_btn1, col_btn2 = st.columns([1, 4])
        with col_btn1:
            if st.button("üîÑ T·∫£i l·∫°i", key="w_t5_refresh"):
                st.session_state.history_cloud = tai_lich_su()
                st.rerun()
        
        # L·∫•y d·ªØ li·ªáu
        data = st.session_state.get("history_cloud", tai_lich_su())
        
        if data:
            df_h = pd.DataFrame(data)
            
            # --- BI·ªÇU ƒê·ªí C·∫¢M X√öC (D√πng t√™n c·ªôt c≈©: Time, SentimentScore) ---
            if "SentimentScore" in df_h.columns:
                try:
                    df_h["score"] = pd.to_numeric(df_h["SentimentScore"], errors='coerce').fillna(0)
                    
                    st.caption("üìâ Bi·ªÉu ƒë·ªì dao ƒë·ªông tr·∫°ng th√°i c·∫£m x√∫c/t∆∞ duy qua th·ªùi gian:")
                    fig = px.line(
                        df_h, 
                        x="Time", 
                        y="score", 
                        markers=True, 
                        color_discrete_sequence=["#76FF03"],
                        labels={"score": "Ch·ªâ s·ªë T√≠ch c·ª±c (Positivity)", "Time": "Th·ªùi gian"}
                    )
                    fig.update_layout(height=250, margin=dict(l=20, r=20, t=10, b=20))
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    # st.warning(f"Kh√¥ng v·∫Ω ƒë∆∞·ª£c bi·ªÉu ƒë·ªì: {e}")
                    pass

            # --- PH·∫¶N 2: T∆Ø DUY BAYES ---
            with st.expander("üîÆ Ph√¢n t√≠ch T∆∞ duy theo x√°c su·∫•t Bayes (E.T. Jaynes)", expanded=False):
                st.info("AI s·∫Ω coi L·ªãch s·ª≠ ho·∫°t ƒë·ªông c·ªßa ch·ªã l√† 'D·ªØ li·ªáu quan s√°t' (Evidence) ƒë·ªÉ suy lu·∫≠n ra 'H√†m m·ª•c ti√™u' (Objective Function) v√† s·ª± d·ªãch chuy·ªÉn ni·ªÅm tin c·ªßa ch·ªã.")
                
                if st.button("üß† Ch·∫°y M√¥ h√¨nh Bayes ngay"):
                    with st.spinner("ƒêang t√≠nh to√°n x√°c su·∫•t h·∫≠u nghi·ªám (Posterior)..."):
                        # L·∫•y 10 ho·∫°t ƒë·ªông g·∫ßn nh·∫•t l√†m d·ªØ li·ªáu m·∫´u
                        recent_logs = df_h.tail(10).to_dict(orient="records")
                        logs_text = json.dumps(recent_logs, ensure_ascii=False)
                        
                        bayes_prompt = f"""
                        ƒê√≥ng vai m·ªôt nh√† khoa h·ªçc t∆∞ duy theo tr∆∞·ªùng ph√°i E.T. Jaynes (s√°ch 'Probability Theory: The Logic of Science').
                        
                        D·ªÆ LI·ªÜU QUAN S√ÅT (EVIDENCE):
                        ƒê√¢y l√† nh·∫≠t k√Ω ho·∫°t ƒë·ªông c·ªßa t√¥i:
                        {logs_text}
                        
                        NHI·ªÜM V·ª§:
                        H√£y ph√¢n t√≠ch chu·ªói h√†nh ƒë·ªông n√†y nh∆∞ m·ªôt b√†i to√°n suy lu·∫≠n Bayes.
                        1. **X√°c ƒë·ªãnh Priors (Ni·ªÅm tin ti√™n nghi·ªám):** D·ª±a tr√™n c√°c h√†nh ƒë·ªông ƒë·∫ßu, t√¥i ƒëang quan t√¢m/tin t∆∞·ªüng ƒëi·ªÅu g√¨?
                        2. **C·∫≠p nh·∫≠t Likelihood (Kh·∫£ nƒÉng):** C√°c h√†nh ƒë·ªông ti·∫øp theo c·ªßng c·ªë hay l√†m y·∫øu ƒëi ni·ªÅm tin ƒë√≥?
                        3. **K·∫øt lu·∫≠n Posterior (H·∫≠u nghi·ªám):** Tr·∫°ng th√°i t∆∞ duy hi·ªán t·∫°i c·ªßa t√¥i ƒëang h·ªôi t·ª• v·ªÅ ƒë√¢u? C√≥ m√¢u thu·∫´n (Inconsistency) n√†o trong logic h√†nh ƒë·ªông kh√¥ng?
                        
                        Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√¢u s·∫Øc, d√πng thu·∫≠t ng·ªØ x√°c su·∫•t nh∆∞ng d·ªÖ hi·ªÉu.
                        """
                        
                        # G·ªçi AI Core (D√πng Pro ƒë·ªÉ suy lu·∫≠n s√¢u)
                        analysis = ai.generate(bayes_prompt, model_type="pro")
                        st.markdown(analysis)

            # --- PH·∫¶N 3: DANH S√ÅCH CHI TI·∫æT ---
            st.divider()
            st.write("üìú **Chi ti·∫øt Nh·∫≠t k√Ω:**")
            
            # ƒê·∫£o ng∆∞·ª£c ƒë·ªÉ xem m·ªõi nh·∫•t tr∆∞·ªõc
            for index, item in df_h.iloc[::-1].iterrows():
                # L·∫•y d·ªØ li·ªáu theo t√™n c·ªôt c≈©
                time_str = str(item.get('Time', ''))
                type_str = str(item.get('Type', ''))
                title_str = str(item.get('Title', ''))
                content_str = str(item.get('Content', ''))
                
                icon = "üìù"
                if "Tranh Bi·ªán" in type_str: icon = "üó£Ô∏è"
                elif "D·ªãch" in type_str: icon = "‚úçÔ∏è"
                elif "Audio" in type_str: icon = "üéôÔ∏è"
                
                with st.expander(f"{icon} {time_str} | {type_str} | {title_str}"):
                    st.markdown(content_str)
                    st.caption(f"Sentiment: {item.get('SentimentLabel', 'Neutral')} ({item.get('SentimentScore', 0)})")
        else:
            st.info(T("t5_empty"))

 # --- üëá D√ÅN ƒê√à ƒêO·∫†N N√ÄY V√ÄO CU·ªêI C√ôNG TAB 5 (THAY CHO ƒêO·∫†N C≈®) ---
        st.divider()
        with st.expander("üõ†Ô∏è C√îNG C·ª§ CHUY·ªÇN NH√Ä (V3 - Fix l·ªói D·∫•u ph·∫©y & T√™n b·∫£ng)", expanded=True):
            st.info("Phi√™n b·∫£n V3: ƒê√£ x·ª≠ l√Ω s·ªë li·ªáu Vi·ªát Nam (0,95 -> 0.95) v√† T√™n b·∫£ng ch·ªØ Hoa.")
            
            uploaded_csv = st.file_uploader("1. T·∫£i file CSV t·ª´ Google Sheet l√™n ƒë√¢y:", type=["csv"])
            
            if uploaded_csv:
                # ƒê·ªçc file CSV
                df_old = pd.read_csv(uploaded_csv)
                # X√≥a kho·∫£ng tr·∫Øng th·ª´a trong t√™n c·ªôt
                df_old.columns = df_old.columns.str.strip()
                
                st.write(f"ƒê√£ t√¨m th·∫•y {len(df_old)} d√≤ng nh·∫≠t k√Ω c≈©.")
                
                if st.button("üöÄ B·∫ÆT ƒê·∫¶U CHUY·ªÇN D·ªÆ LI·ªÜU"):
                    progress_bar = st.progress(0)
                    success_count = 0
                    error_count = 0
                    errors_log = [] 
                    
                    for idx, row in df_old.iterrows():
                        try:
                            # 1. X·ª¨ L√ù NG√ÄY TH√ÅNG
                            raw_time = str(row.get('Time', '')).strip()
                            clean_time = datetime.now().isoformat()
                            if raw_time and raw_time.lower() != 'nan':
                                try:
                                    clean_time = pd.to_datetime(raw_time).strftime('%Y-%m-%d %H:%M:%S')
                                except: pass

                            # 2. X·ª¨ L√ù S·ªê LI·ªÜU (FIX L·ªñI 0,95)
                            raw_score = str(row.get('SentimentScore', '0'))
                            # üëâ Thay d·∫•u ph·∫©y th√†nh d·∫•u ch·∫•m ngay l·∫≠p t·ª©c
                            clean_score = raw_score.replace(',', '.')
                            try:
                                final_score = float(clean_score)
                            except:
                                final_score = 0.0

                            data = {
                                "created_at": clean_time,
                                "type": str(row.get('Type', 'General')),
                                "title": str(row.get('Title', 'No Title')),
                                "content": str(row.get('Content', '')),
                                "user_name": str(row.get('User', 'Imported')),
                                "sentiment_score": final_score, # ‚úÖ ƒê√£ s·∫°ch
                                "sentiment_label": str(row.get('SentimentLabel', 'Neutral'))
                            }
                            
                            # 3. G·ª¨I L√äN SUPABASE (D√πng History_Logs ch·ªØ Hoa nh∆∞ l·ªói g·ª£i √Ω)
                            try:
                                supabase.table("History_Logs").insert(data).execute()
                            except:
                                # N·∫øu History_Logs l·ªói th√¨ th·ª≠ l·∫°i history_logs (ph√≤ng h·ªù)
                                supabase.table("history_logs").insert(data).execute()
                                
                            success_count += 1
                            
                        except Exception as e:
                            error_count += 1
                            errors_log.append(f"D√≤ng {idx}: {str(e)}")
                        
                        progress_bar.progress((idx + 1) / len(df_old))
                    
                    st.success(f"‚úÖ ƒê√£ chuy·ªÉn th√†nh c√¥ng: {success_count} d√≤ng.")
                    
                    if error_count > 0:
                        st.error(f"‚ö†Ô∏è C√≥ {error_count} d√≤ng b·ªã l·ªói.")
                        with st.expander("Xem chi ti·∫øt l·ªói"):
                            for err in errors_log:
                                st.write(err)
                    else:
                        st.balloons()
                        time.sleep(1)
                        st.rerun()
