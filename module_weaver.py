import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pypdf import PdfReader
from docx import Document
from bs4 import BeautifulSoup
from streamlit_agraph import agraph, Node, Edge, Config
import plotly.express as px
import time
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
import json
import re

# --- IMPORT CÃC META-BLOCKS ---
from ai_core import AI_Core
from voice_block import Voice_Engine
from prompts import DEBATE_PERSONAS, BOOK_ANALYSIS_PROMPT

# ==========================================
# ğŸŒ Bá»˜ Tá»ª ÄIá»‚N ÄA NGÃ”N NGá»® (TÃCH Há»¢P VÃ€O MODULE)
# ==========================================
TRANS = {
    "vi": {
        "lang_select": "NgÃ´n ngá»¯ / Language / è¯­è¨€",
        "tab1": "ğŸ“š PhÃ¢n TÃ­ch SÃ¡ch",
        "tab2": "âœï¸ Dá»‹ch Giáº£",
        "tab3": "ğŸ—£ï¸ Tranh Biá»‡n",
        "tab4": "ğŸ™ï¸ PhÃ²ng Thu AI",
        "tab5": "â³ Nháº­t KÃ½",
        "t1_header": "Trá»£ lÃ½ NghiÃªn cá»©u & Knowledge Graph",
        "t1_up_excel": "1. Káº¿t ná»‘i Kho SÃ¡ch (Excel)",
        "t1_up_doc": "2. TÃ i liá»‡u má»›i (PDF/Docx)",
        "t1_btn": "ğŸš€ PHÃ‚N TÃCH NGAY",
        "t1_analyzing": "Äang phÃ¢n tÃ­ch {name}...",
        "t2_header": "Dá»‹ch Thuáº­t Äa Chiá»u",
        "t2_input": "Nháº­p vÄƒn báº£n cáº§n dá»‹ch:",
        "t2_target": "Dá»‹ch sang:",
        "t2_style": "Phong cÃ¡ch:",
        "t2_btn": "âœï¸ Dá»‹ch Ngay",
        "t3_header": "Äáº¥u TrÆ°á»ng TÆ° Duy",
        "t3_persona_label": "Chá»n Äá»‘i Thá»§:",
        "t3_input": "Nháº­p chá»§ Ä‘á» tranh luáº­n...",
        "t3_clear": "ğŸ—‘ï¸ XÃ³a Chat",
        "t4_header": "ğŸ™ï¸ PhÃ²ng Thu AI Äa NgÃ´n Ngá»¯",
        "t4_voice": "Chá»n Giá»ng:",
        "t4_speed": "Tá»‘c Ä‘á»™:",
        "t4_btn": "ğŸ”Š Táº O AUDIO",
        "t5_header": "Nháº­t KÃ½ & Lá»‹ch Sá»­",
        "t5_refresh": "ğŸ”„ Táº£i láº¡i Lá»‹ch sá»­",
        "t5_empty": "ChÆ°a cÃ³ dá»¯ liá»‡u lá»‹ch sá»­.",
    },
    "en": {
        "lang_select": "Language",
        "tab1": "ğŸ“š Book Analysis",
        "tab2": "âœï¸ Translator",
        "tab3": "ğŸ—£ï¸ Debater",
        "tab4": "ğŸ™ï¸ AI Studio",
        "tab5": "â³ History",
        "t1_header": "Research Assistant & Knowledge Graph",
        "t1_up_excel": "1. Connect Book Database (Excel)",
        "t1_up_doc": "2. New Documents (PDF/Docx)",
        "t1_btn": "ğŸš€ ANALYZE NOW",
        "t1_analyzing": "Analyzing {name}...",
        "t2_header": "Multidimensional Translator",
        "t2_input": "Enter text to translate:",
        "t2_target": "Translate to:",
        "t2_style": "Style:",
        "t2_btn": "âœï¸ Translate",
        "t3_header": "Thinking Arena",
        "t3_persona_label": "Choose Opponent:",
        "t3_input": "Enter debate topic...",
        "t3_clear": "ğŸ—‘ï¸ Clear Chat",
        "t4_header": "ğŸ™ï¸ Multilingual AI Studio",
        "t4_voice": "Select Voice:",
        "t4_speed": "Speed:",
        "t4_btn": "ğŸ”Š GENERATE AUDIO",
        "t5_header": "Logs & History",
        "t5_refresh": "ğŸ”„ Refresh History",
        "t5_empty": "No history data found.",
    },
    "zh": {
        "lang_select": "è¯­è¨€",
        "tab1": "ğŸ“š ä¹¦ç±åˆ†æ",
        "tab2": "âœï¸ ç¿»è¯‘ä¸“å®¶",
        "tab3": "ğŸ—£ï¸ è¾©è®ºåœº",
        "tab4": "ğŸ™ï¸ AI å½•éŸ³å®¤",
        "tab5": "â³ å†å²è®°å½•",
        "t1_header": "ç ”ç©¶åŠ©æ‰‹ & çŸ¥è¯†å›¾è°±",
        "t1_up_excel": "1. è¿æ¥ä¹¦åº“ (Excel)",
        "t1_up_doc": "2. ä¸Šä¼ æ–°æ–‡æ¡£ (PDF/Docx)",
        "t1_btn": "ğŸš€ ç«‹å³åˆ†æ",
        "t1_analyzing": "æ­£åœ¨åˆ†æ {name}...",
        "t2_header": "å¤šç»´ç¿»è¯‘",
        "t2_input": "è¾“å…¥æ–‡æœ¬:",
        "t2_target": "ç¿»è¯‘æˆ:",
        "t2_style": "é£æ ¼:",
        "t2_btn": "âœï¸ ç¿»è¯‘",
        "t3_header": "æ€ç»´ç«æŠ€åœº",
        "t3_persona_label": "é€‰æ‹©å¯¹æ‰‹:",
        "t3_input": "è¾“å…¥è¾©è®ºä¸»é¢˜...",
        "t3_clear": "ğŸ—‘ï¸ æ¸…é™¤èŠå¤©",
        "t4_header": "ğŸ™ï¸ AI å¤šè¯­è¨€å½•éŸ³å®¤",
        "t4_voice": "é€‰æ‹©å£°éŸ³:",
        "t4_speed": "è¯­é€Ÿ:",
        "t4_btn": "ğŸ”Š ç”ŸæˆéŸ³é¢‘",
        "t5_header": "æ—¥å¿— & å†å²",
        "t5_refresh": "ğŸ”„ åˆ·æ–°å†å²",
        "t5_empty": "æš‚æ— å†å²æ•°æ®ã€‚",
    }
}

# HÃ m láº¥y text theo ngÃ´n ngá»¯
def T(key):
    lang = st.session_state.get('weaver_lang', 'vi')
    return TRANS.get(lang, TRANS['vi']).get(key, key)

# --- CÃC HÃ€M PHá»¤ TRá»¢ ---
@st.cache_resource
def load_models():
    return SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

def doc_file(uploaded_file):
    if not uploaded_file: return ""
    ext = uploaded_file.name.split('.')[-1].lower()
    try:
        if ext == "pdf":
            reader = PdfReader(uploaded_file)
            return "\n".join([page.extract_text() for page in reader.pages])
        elif ext == "docx":
            doc = Document(uploaded_file)
            return "\n".join([p.text for p in doc.paragraphs])
        elif ext in ["txt", "md", "html"]:
            return str(uploaded_file.read(), "utf-8")
    except: return ""
    return ""

def connect_gsheet():
    try:
        if "gcp_service_account" not in st.secrets: return None
        creds_dict = dict(st.secrets["gcp_service_account"])
        if "private_key" in creds_dict:
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        return client.open("AI_History_Logs").sheet1
    except: return None

def luu_lich_su(loai, tieu_de, noi_dung):
    thoi_gian = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    user = st.session_state.get("current_user", "Unknown")
    try:
        sheet = connect_gsheet()
        if sheet: sheet.append_row([thoi_gian, loai, tieu_de, noi_dung, user, 0.0, "Neutral"])
    except: pass

def tai_lich_su():
    try:
        sheet = connect_gsheet()
        if sheet: return sheet.get_all_records()
    except: return []
    return []

# --- HÃ€M CHÃNH: RUN() ---
def run():
    # 1. Khá»Ÿi táº¡o cÃ¡c Block
    ai = AI_Core()
    voice = Voice_Engine()
    
    # 2. Sidebar chá»n ngÃ´n ngá»¯ cho Module nÃ y
    with st.sidebar:
        st.markdown("---")
        lang_choice = st.selectbox(
            "ğŸŒ " + TRANS['vi']['lang_select'],
            ["Tiáº¿ng Viá»‡t", "English", "ä¸­æ–‡"],
            index=0,
            key="weaver_lang_selector"
        )
        # LÆ°u ngÃ´n ngá»¯ vÃ o session state
        if lang_choice == "Tiáº¿ng Viá»‡t": st.session_state.weaver_lang = 'vi'
        elif lang_choice == "English": st.session_state.weaver_lang = 'en'
        elif lang_choice == "ä¸­æ–‡": st.session_state.weaver_lang = 'zh'
    
    st.header(f"ğŸ§  {T('The Cognitive Weaver')}")
    
    # 5 TABS Äáº¦Y Äá»¦ (DÃ¹ng hÃ m T Ä‘á»ƒ dá»‹ch tÃªn Tab)
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        T("tab1"), T("tab2"), T("tab3"), T("tab4"), T("tab5")
    ])

    # === TAB 1: RAG & GRAPH ===
    with tab1:
        st.subheader(T("t1_header"))
        
        c1, c2, c3 = st.columns([1, 1, 1])
        with c1: file_excel = st.file_uploader(T("t1_up_excel"), type="xlsx", key="w_t1_ex")
        with c2: uploaded_files = st.file_uploader(T("t1_up_doc"), type=["pdf", "docx", "txt"], accept_multiple_files=True, key="w_t1_doc")
        with c3: 
            st.write("")
            st.write("")
            btn_run = st.button(T("t1_btn"), type="primary", use_container_width=True)

        if btn_run and uploaded_files:
            vec = load_models()
            db, df = None, None
            has_db = False
            
            if file_excel:
                try:
                    df = pd.read_excel(file_excel).dropna(subset=["TÃªn sÃ¡ch"])
                    db = vec.encode([f"{r['TÃªn sÃ¡ch']} {str(r.get('Cáº¢M NHáº¬N',''))}" for _, r in df.iterrows()])
                    has_db = True
                    st.success(T("t1_connect_ok").format(n=len(df)))
                except: st.error("Lá»—i Ä‘á»c Excel.")

            for f in uploaded_files:
                text = doc_file(f)
                link = ""
                if has_db:
                    q = vec.encode([text[:2000]])
                    sc = cosine_similarity(q, db)[0]
                    idx = np.argsort(sc)[::-1][:3]
                    for i in idx:
                        if sc[i] > 0.35: link += f"- {df.iloc[i]['TÃªn sÃ¡ch']} ({sc[i]*100:.0f}%)\n"

                with st.spinner(T("t1_analyzing").format(name=f.name)):
                    prompt = f"PhÃ¢n tÃ­ch tÃ i liá»‡u '{f.name}'. LiÃªn quan: {link}\nNá»™i dung: {text[:30000]}"
                    res = ai.analyze_static(prompt, BOOK_ANALYSIS_PROMPT)
                    
                    st.markdown(f"### ğŸ“„ {f.name}")
                    st.markdown(res)
                    st.markdown("---")
                    luu_lich_su("PhÃ¢n TÃ­ch SÃ¡ch", f.name, res[:200])

        # Váº¼ GRAPH (AGRAPH)
        if file_excel:
            try:
                with st.expander(T("t1_graph_title"), expanded=False):
                    vec = load_models()
                    if "book_embs" not in st.session_state:
                         st.session_state.book_embs = vec.encode(df["TÃªn sÃ¡ch"].tolist())
                    
                    embs = st.session_state.book_embs
                    sim = cosine_similarity(embs)
                    nodes, edges = [], []
                    
                    max_nodes = st.slider("Max Nodes:", 5, len(df), min(50, len(df)))
                    threshold = st.slider("Threshold:", 0.0, 1.0, 0.45)

                    for i in range(max_nodes):
                        nodes.append(Node(id=str(i), label=df.iloc[i]["TÃªn sÃ¡ch"], size=20, color="#FFD166"))
                        for j in range(i+1, max_nodes):
                            if sim[i,j]>threshold: edges.append(Edge(source=str(i), target=str(j), color="#118AB2"))
                    
                    config = Config(width=900, height=600, directed=False, physics=True, collapsible=False)
                    agraph(nodes, edges, config)
            except: pass

    # === TAB 2: Dá»ŠCH GIáº¢ ===
    with tab2:
        st.subheader(T("t2_header"))
        txt = st.text_area(T("t2_input"), height=150, key="w_t2_inp")
        c_l, c_s, c_b = st.columns([1,1,1])
        with c_l: target_lang = st.selectbox(T("t2_target"), ["Tiáº¿ng Viá»‡t", "English", "Chinese", "French", "Japanese"], key="w_t2_lang")
        with c_s: style = st.selectbox(T("t2_style"), ["Default", "Academic", "Literary", "Business"], key="w_t2_style")
        
        if st.button(T("t2_btn"), key="w_t2_btn") and txt:
            with st.spinner("AI Translating..."):
                p = f"Translate to {target_lang}. Style: {style}. Text: {txt}"
                res = ai.generate(p, model_type="pro")
                st.markdown(res)
                luu_lich_su("Dá»‹ch Thuáº­t", f"{target_lang}", txt[:50])

    # === TAB 3: Äáº¤U TRÆ¯á»œNG TÆ¯ DUY (MULTI-AGENT ARENA) ===
    with tab3:
        st.subheader(T("t3_header"))
        mode = st.radio("Mode:", ["ğŸ‘¤ Solo", "âš”ï¸ Multi-Agent"], horizontal=True, key="w_t3_mode")
        
        if "weaver_chat" not in st.session_state: st.session_state.weaver_chat = []

        if mode == "ğŸ‘¤ Solo":
            c1, c2 = st.columns([3, 1])
            with c1: persona = st.selectbox(T("t3_persona_label"), list(DEBATE_PERSONAS.keys()), key="w_t3_solo_p")
            with c2: 
                if st.button(T("t3_clear"), key="w_t3_clr"): 
                    st.session_state.weaver_chat = []
                    st.rerun()

            for msg in st.session_state.weaver_chat:
                st.chat_message(msg["role"]).write(msg["content"])

            if prompt := st.chat_input(T("t3_input")):
                st.chat_message("user").write(prompt)
                st.session_state.weaver_chat.append({"role": "user", "content": prompt})
                
                with st.chat_message("assistant"):
                    sys = DEBATE_PERSONAS[persona]
                    with st.spinner("..."):
                        res = ai.generate(prompt, model_type="flash", system_instruction=sys)
                        st.write(res)
                        st.session_state.weaver_chat.append({"role": "assistant", "content": res})
                        luu_lich_su("Tranh Biá»‡n Solo", persona, prompt)
        # --- PHáº¦N Há»˜I Äá»’NG TRANH BIá»†N (ÄÃƒ Sá»¬A) ---
        else:
            st.info("ğŸ’¡ Chá»n tá»‘i Ä‘a 3 nhÃ¢n váº­t Ä‘á»ƒ há» tá»± cÃ£i nhau.")
            participants = st.multiselect(
                "Chá»n Há»™i Äá»“ng Tranh Biá»‡n:", 
                list(DEBATE_PERSONAS.keys()), 
                default=[list(DEBATE_PERSONAS.keys())[0], list(DEBATE_PERSONAS.keys())[1]],
                key="w_t3_multi_p"
            )
            topic = st.text_input("Chá»§ Ä‘á» tranh luáº­n:", key="w_t3_topic")
            
            c_start, c_del = st.columns([1, 5])
            with c_start:
                start_btn = st.button("ğŸ”¥ KHAI CHIáº¾N", key="w_t3_start", disabled=(len(participants)<2))
            with c_del:
                if st.button("ğŸ—‘ï¸ XÃ³a BÃ n", key="w_t3_multi_clr"):
                    st.session_state.weaver_chat = []
                    st.rerun()

            # Hiá»‡n lá»‹ch sá»­ cÅ© Ä‘á»ƒ khÃ´ng bá»‹ máº¥t khi rerun
            for msg in st.session_state.weaver_chat:
                if msg["role"] == "system":
                    st.chat_message("system").write(msg["content"])
                elif msg["role"] == "assistant":
                    st.chat_message("assistant").write(msg["content"])

            # Logic cháº¡y vÃ²ng láº·p
            if start_btn and topic:
                st.session_state.weaver_chat = [] # Reset
                
                start_msg = f"ğŸ“¢ **CHá»¦ Tá»ŒA:** Báº¯t Ä‘áº§u tranh luáº­n vá»: *{topic}*"
                st.session_state.weaver_chat.append({"role": "system", "content": start_msg})
                st.chat_message("system").write(start_msg)
                
                # Biáº¿n táº¡m Ä‘á»ƒ lÆ°u log cho hÃ m luu_lich_su
                full_transcript = [start_msg]

                with st.status("Cuá»™c chiáº¿n Ä‘ang diá»…n ra (3 vÃ²ng)...") as status:
                    for round_num in range(1, 4):
                        status.update(label=f"ğŸ”„ VÃ²ng {round_num}/3...")
                        for p_name in participants:
                            # XÃ¢y dá»±ng ngá»¯ cáº£nh tá»« tin nháº¯n cuá»‘i cÃ¹ng
                            last_content = st.session_state.weaver_chat[-1]['content'] if st.session_state.weaver_chat else topic
                            
                            p_prompt = f"""
                            VAI TRÃ’: {p_name}. 
                            CHá»¦ Äá»€ Gá»C: {topic}.
                            TÃŒNH HUá»NG: NgÆ°á»i trÆ°á»›c vá»«a nÃ³i: '{last_content}'.
                            NHIá»†M Vá»¤: HÃ£y pháº£n biá»‡n hoáº·c bá»• sung Ã½ kiáº¿n ngáº¯n gá»n (dÆ°á»›i 100 tá»«).
                            """
                            
                            # Gá»i AI
                            res = ai.generate(p_prompt, model_type="flash", system_instruction=DEBATE_PERSONAS[p_name])
                            
                            # LÆ°u vÃ  Hiá»‡n
                            content_fmt = f"**{p_name}:** {res}"
                            st.session_state.weaver_chat.append({"role": "assistant", "content": content_fmt})
                            full_transcript.append(content_fmt)
                            
                            with st.chat_message("assistant"): 
                                st.write(content_fmt)
                            
                            time.sleep(10) # Nghá»‰ Ä‘á»ƒ trÃ¡nh Quota
                
                # --- ÄÃƒ Bá»” SUNG: LÆ¯U Lá»ŠCH Sá»¬ ---
                luu_lich_su("Há»™i Äá»“ng Tranh Biá»‡n", topic, "\n\n".join(full_transcript))
                st.success("Káº¿t thÃºc tranh luáº­n! ÄÃ£ lÆ°u vÃ o Nháº­t kÃ½.")

    # === TAB 4: PHÃ’NG THU AI ===
    with tab4:
        st.subheader(T("t4_header"))
        c_in, c_ctrl = st.columns([3, 1])
        with c_in: inp_v = st.text_area("Text:", height=200, key="w_t4_input")
        with c_ctrl:
            try:
                v_choice = st.selectbox(T("t4_voice"), list(voice.VOICE_OPTIONS.keys()), key="w_t4_sel")
            except:
                v_choice = st.selectbox(T("t4_voice"), ["vi", "en"], key="w_t4_sel")
            speed_v = st.slider(T("t4_speed"), -50, 50, 0, key="w_t4_spd")
        
        if st.button(T("t4_btn"), key="w_t4_btn") and inp_v:
            with st.spinner("..."):
                path = voice.speak(inp_v, voice_key=v_choice, speed=speed_v)
                if path:
                    st.audio(path)
                    st.success("OK")

    # === TAB 5: NHáº¬T KÃ & TÆ¯ DUY BAYES ===
    with tab5:
        st.subheader("â³ Nháº­t KÃ½ & Pháº£n Chiáº¿u TÆ° Duy")
        
        col_btn1, col_btn2 = st.columns([1, 4])
        with col_btn1:
            if st.button("ğŸ”„ Táº£i láº¡i", key="w_t5_refresh"):
                st.session_state.history_cloud = tai_lich_su()
                st.rerun()
        
        # Láº¥y dá»¯ liá»‡u
        data = st.session_state.get("history_cloud", tai_lich_su())
        
        if data:
            df_h = pd.DataFrame(data)
            
            # --- PHáº¦N 1: KHÃ”I PHá»¤C BIá»‚U Äá»’ Cáº¢M XÃšC (SENTIMENT CHART) ---
            if "SentimentScore" in df_h.columns:
                try:
                    # Chuyá»ƒn Ä‘á»•i sang sá»‘, xá»­ lÃ½ lá»—i náº¿u cÃ³ dÃ²ng trá»‘ng
                    df_h["score"] = pd.to_numeric(df_h["SentimentScore"], errors='coerce').fillna(0)
                    
                    st.caption("ğŸ“‰ Biá»ƒu Ä‘á»“ dao Ä‘á»™ng tráº¡ng thÃ¡i cáº£m xÃºc/tÆ° duy qua thá»i gian:")
                    fig = px.line(
                        df_h, 
                        x="Time", 
                        y="score", 
                        markers=True, 
                        color_discrete_sequence=["#76FF03"], # <--- MÃ£ mÃ u Xanh NÃµn Chuá»‘i (Neon)
                        # Náº¿u thÃ­ch Xanh DÆ°Æ¡ng thÃ¬ thay báº±ng: ["#1E90FF"]
                        # color="SentimentLabel", # <--- Tá»± Ä‘á»™ng chia mÃ u theo cá»™t Label
                        labels={"score": "Chá»‰ sá»‘ TÃ­ch cá»±c (Positivity)", "Time": "Thá»i gian"}
                    )
                    fig.update_layout(height=250, margin=dict(l=20, r=20, t=10, b=20))
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.warning(f"KhÃ´ng váº½ Ä‘Æ°á»£c biá»ƒu Ä‘á»“: {e}")

            # --- PHáº¦N 2: TÆ¯ DUY BAYES (THE JAYNESIAN ANALYZER) - Má»šI ---
            with st.expander("ğŸ”® PhÃ¢n tÃ­ch TÆ° duy theo xÃ¡c suáº¥t Bayes (E.T. Jaynes)", expanded=False):
                st.info("AI sáº½ coi Lá»‹ch sá»­ hoáº¡t Ä‘á»™ng cá»§a chá»‹ lÃ  'Dá»¯ liá»‡u quan sÃ¡t' (Evidence) Ä‘á»ƒ suy luáº­n ra 'HÃ m má»¥c tiÃªu' (Objective Function) vÃ  sá»± dá»‹ch chuyá»ƒn niá»m tin cá»§a chá»‹.")
                
                if st.button("ğŸ§  Cháº¡y MÃ´ hÃ¬nh Bayes ngay"):
                    with st.spinner("Äang tÃ­nh toÃ¡n xÃ¡c suáº¥t háº­u nghiá»‡m (Posterior)..."):
                        # Láº¥y 10 hoáº¡t Ä‘á»™ng gáº§n nháº¥t lÃ m dá»¯ liá»‡u máº«u
                        recent_logs = df_h.tail(10).to_dict(orient="records")
                        logs_text = json.dumps(recent_logs, ensure_ascii=False)
                        
                        bayes_prompt = f"""
                        ÄÃ³ng vai má»™t nhÃ  khoa há»c tÆ° duy theo trÆ°á»ng phÃ¡i E.T. Jaynes (sÃ¡ch 'Probability Theory: The Logic of Science').
                        
                        Dá»® LIá»†U QUAN SÃT (EVIDENCE):
                        ÄÃ¢y lÃ  nháº­t kÃ½ hoáº¡t Ä‘á»™ng cá»§a tÃ´i:
                        {logs_text}
                        
                        NHIá»†M Vá»¤:
                        HÃ£y phÃ¢n tÃ­ch chuá»—i hÃ nh Ä‘á»™ng nÃ y nhÆ° má»™t bÃ i toÃ¡n suy luáº­n Bayes.
                        1. **XÃ¡c Ä‘á»‹nh Priors (Niá»m tin tiÃªn nghiá»‡m):** Dá»±a trÃªn cÃ¡c hÃ nh Ä‘á»™ng Ä‘áº§u, tÃ´i Ä‘ang quan tÃ¢m/tin tÆ°á»Ÿng Ä‘iá»u gÃ¬?
                        2. **Cáº­p nháº­t Likelihood (Kháº£ nÄƒng):** CÃ¡c hÃ nh Ä‘á»™ng tiáº¿p theo cá»§ng cá»‘ hay lÃ m yáº¿u Ä‘i niá»m tin Ä‘Ã³?
                        3. **Káº¿t luáº­n Posterior (Háº­u nghiá»‡m):** Tráº¡ng thÃ¡i tÆ° duy hiá»‡n táº¡i cá»§a tÃ´i Ä‘ang há»™i tá»¥ vá» Ä‘Ã¢u? CÃ³ mÃ¢u thuáº«n (Inconsistency) nÃ o trong logic hÃ nh Ä‘á»™ng khÃ´ng?
                        
                        Tráº£ lá»i ngáº¯n gá»n, sÃ¢u sáº¯c, dÃ¹ng thuáº­t ngá»¯ xÃ¡c suáº¥t nhÆ°ng dá»… hiá»ƒu.
                        """
                        
                        # Gá»i AI Core (DÃ¹ng Pro Ä‘á»ƒ suy luáº­n sÃ¢u)
                        analysis = ai.generate(bayes_prompt, model_type="pro")
                        st.markdown(analysis)

            # --- PHáº¦N 3: DANH SÃCH CHI TIáº¾T ---
            st.divider()
            st.write("ğŸ“œ **Chi tiáº¿t Nháº­t kÃ½:**")
            
            # Äáº£o ngÆ°á»£c Ä‘á»ƒ xem má»›i nháº¥t trÆ°á»›c
            for index, item in df_h.iloc[::-1].iterrows():
                time_str = str(item.get('Time', ''))
                type_str = str(item.get('Type', ''))
                title_str = str(item.get('Title', ''))
                content_str = str(item.get('Content', ''))
                
                icon = "ğŸ“"
                if "Tranh Biá»‡n" in type_str: icon = "ğŸ—£ï¸"
                elif "Dá»‹ch" in type_str: icon = "âœï¸"
                elif "Audio" in type_str: icon = "ğŸ™ï¸"
                
                with st.expander(f"{icon} {time_str} | {type_str} | {title_str}"):
                    st.markdown(content_str)
                    st.caption(f"Sentiment: {item.get('SentimentLabel', 'Neutral')} ({item.get('SentimentScore', 0)})")
        else:
            st.info(T("t5_empty"))
